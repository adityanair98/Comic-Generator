{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANGA Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation data\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize((256, 256)), # Resize to 224x224\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]), # Normalize\n",
    "])\n",
    "\n",
    "# Create Datasets for Training and Validation\n",
    "PATH = './animeface-character-dataset/animeface-character-dataset' \n",
    "train_dataset = ImageFolder(PATH, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 9754\n",
       "    Root location: ./animeface-character-dataset/animeface-character-dataset\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "                 Resize(size=[256, 256], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
       "                 ToTensor()\n",
       "                 Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], inplace=False)\n",
       "           )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for batching and shuffling the data\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, maps = 64, noise_size = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(noise_size, maps * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(maps * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (maps*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(maps * 8, maps * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(maps * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (maps*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(maps * 4, maps * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(maps * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (maps*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(maps * 2, maps, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(maps),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (maps) x 32 x 32\n",
    "            nn.ConvTranspose2d(maps, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "noise = torch.randn(64, 128, 1, 1)\n",
    "output = generator(noise)\n",
    "plt.imshow(output[0].detach().numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
